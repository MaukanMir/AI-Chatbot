{"cells":[{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading collection 'popular'\n","[nltk_data]    | \n","[nltk_data]    | Downloading package cmudict to\n","[nltk_data]    |     /Users/test/nltk_data...\n","[nltk_data]    |   Unzipping corpora/cmudict.zip.\n","[nltk_data]    | Downloading package gazetteers to\n","[nltk_data]    |     /Users/test/nltk_data...\n","[nltk_data]    |   Unzipping corpora/gazetteers.zip.\n","[nltk_data]    | Downloading package genesis to\n","[nltk_data]    |     /Users/test/nltk_data...\n","[nltk_data]    |   Unzipping corpora/genesis.zip.\n","[nltk_data]    | Downloading package gutenberg to\n","[nltk_data]    |     /Users/test/nltk_data...\n","[nltk_data]    |   Unzipping corpora/gutenberg.zip.\n","[nltk_data]    | Downloading package inaugural to\n","[nltk_data]    |     /Users/test/nltk_data...\n","[nltk_data]    |   Unzipping corpora/inaugural.zip.\n","[nltk_data]    | Downloading package movie_reviews to\n","[nltk_data]    |     /Users/test/nltk_data...\n","[nltk_data]    |   Unzipping corpora/movie_reviews.zip.\n","[nltk_data]    | Downloading package names to /Users/test/nltk_data...\n","[nltk_data]    |   Unzipping corpora/names.zip.\n","[nltk_data]    | Downloading package shakespeare to\n","[nltk_data]    |     /Users/test/nltk_data...\n","[nltk_data]    |   Unzipping corpora/shakespeare.zip.\n","[nltk_data]    | Downloading package stopwords to\n","[nltk_data]    |     /Users/test/nltk_data...\n","[nltk_data]    |   Unzipping corpora/stopwords.zip.\n","[nltk_data]    | Downloading package treebank to\n","[nltk_data]    |     /Users/test/nltk_data...\n","[nltk_data]    |   Unzipping corpora/treebank.zip.\n","[nltk_data]    | Downloading package twitter_samples to\n","[nltk_data]    |     /Users/test/nltk_data...\n","[nltk_data]    |   Unzipping corpora/twitter_samples.zip.\n","[nltk_data]    | Downloading package omw to /Users/test/nltk_data...\n","[nltk_data]    | Downloading package omw-1.4 to\n","[nltk_data]    |     /Users/test/nltk_data...\n","[nltk_data]    | Downloading package wordnet to\n","[nltk_data]    |     /Users/test/nltk_data...\n","[nltk_data]    | Downloading package wordnet2021 to\n","[nltk_data]    |     /Users/test/nltk_data...\n","[nltk_data]    | Downloading package wordnet31 to\n","[nltk_data]    |     /Users/test/nltk_data...\n","[nltk_data]    | Downloading package wordnet_ic to\n","[nltk_data]    |     /Users/test/nltk_data...\n","[nltk_data]    |   Unzipping corpora/wordnet_ic.zip.\n","[nltk_data]    | Downloading package words to /Users/test/nltk_data...\n","[nltk_data]    |   Unzipping corpora/words.zip.\n","[nltk_data]    | Downloading package maxent_ne_chunker to\n","[nltk_data]    |     /Users/test/nltk_data...\n","[nltk_data]    |   Unzipping chunkers/maxent_ne_chunker.zip.\n","[nltk_data]    | Downloading package punkt to /Users/test/nltk_data...\n","[nltk_data]    |   Unzipping tokenizers/punkt.zip.\n","[nltk_data]    | Downloading package snowball_data to\n","[nltk_data]    |     /Users/test/nltk_data...\n","[nltk_data]    | Downloading package averaged_perceptron_tagger to\n","[nltk_data]    |     /Users/test/nltk_data...\n","[nltk_data]    |   Unzipping taggers/averaged_perceptron_tagger.zip.\n","[nltk_data]    | \n","[nltk_data]  Done downloading collection popular\n"]}],"source":["import random\n","import json \n","import pickle\n","import numpy as np\n","import json\n","\n","import nltk\n","nltk.download('popular')\n","from nltk.stem import WordNetLemmatizer\n","\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Activation, Dropout\n","from tensorflow.keras.optimizers import SGD"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":["lemmatizer = WordNetLemmatizer()\n","intents =json.loads(open(\"intents.json\").read())\n","\n","words = []\n","classes = []\n","documents = []\n","ignore_letters = [\"?\", \"!\", \".\",\",\"]\n","\n","for intent in intents[\"intents\"]:\n","  for pattern in intent[\"patterns\"]:\n","    word_list = nltk.word_tokenize(pattern)\n","    words.extend(word_list)\n","    documents.append((word_list,intent[\"tag\"]))\n","    if intent[\"tag\"] not in classes:\n","      classes.append(intent[\"tag\"])\n","  "]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[],"source":["words = sorted(set([lemmatizer.lemmatize(word) for word in words if word not in ignore_letters]))"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[{"data":{"text/plain":["['Best',\n"," 'Can',\n"," 'Good',\n"," 'Goodbye',\n"," 'Have',\n"," 'Hello',\n"," 'Hey',\n"," 'Hi',\n"," 'How',\n"," 'I',\n"," 'Is',\n"," 'Leaving',\n"," 'See',\n"," 'Show',\n"," 'Tell',\n"," 'What',\n"," 'Whats',\n"," 'Where',\n"," 'Which',\n"," 'a',\n"," 'about',\n"," 'am',\n"," 'anyone',\n"," 'are',\n"," 'bye',\n"," 'can',\n"," 'cao',\n"," 'code',\n"," 'coding',\n"," 'cya',\n"," 'day',\n"," 'development',\n"," 'do',\n"," 'good',\n"," 'greeting',\n"," 'is',\n"," 'later',\n"," 'learn',\n"," 'me',\n"," 'my',\n"," 'own',\n"," 'portfolio',\n"," 'progamming',\n"," 'programming',\n"," 'recommend',\n"," 'resource',\n"," 'see',\n"," 'software',\n"," 'stock',\n"," 'there',\n"," 'to',\n"," 'up',\n"," 'way',\n"," 'ya',\n"," 'you']"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["words"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[],"source":["classes = sorted(set(classes))\n","pickle.dump(words, open(\"words.pkl\",\"wb\"))\n","pickle.dump(words, open(\"classes.pkl\",\"wb\"))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.8"}},"nbformat":4,"nbformat_minor":2}
